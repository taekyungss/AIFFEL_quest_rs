{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary as torch_summary\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 32, 32])\n",
      "Label: 6\n",
      "Number of classes: 10\n",
      "Train dataset size: 50000 (Shape: torch.Size([]))\n",
      "Test dataset size: 10000 (Shape: torch.Size([]))\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 로드하고 기본 정보를 확인해 보세요.\n",
    "image, label = trainset[0]\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Number of classes: {len(trainset.classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(trainset.classes)\n",
    "print(num_classes)\n",
    "\n",
    "class_names = trainset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super().__init__()\n",
    "        self.lambd = lambd\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"ResNet-18, 34에서 사용\"\"\"\n",
    "    # channel 확장시킬떄 사용 expansion\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, option='B'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # LLM과 함께 짠 코드 (채널수가 변경될 경우 shortcut연산이 안될 수 있음)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        #크기가 같을때는 x와 동일, 크기가 다를때 크기/채널 조정하도록\n",
    "\n",
    "        # stride 가 1이 아님 (공간 변화) or 채널수가 변하는 경우\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "\n",
    "            if option == 'A': \n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(\n",
    "                        x[:, :, ::stride, ::stride], # stride로 다운샘플링\n",
    "                        (0, 0, 0, 0, 0, out_channels * self.expansion - in_channels),# 채널 zero-padding\n",
    "                        \"constant\", 0\n",
    "                    )\n",
    "                )\n",
    "            elif option == 'B':\n",
    "                # Option B: Projection shortcut (차원 변경시만 1×1 conv)\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels * self.expansion,\n",
    "                            kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels * self.expansion)\n",
    "                )\n",
    "\n",
    "            elif option ==\"C\":\n",
    "            # 이 경우는 stride=1, 채널 동일해도 projection 사용\n",
    "                pass                \n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        identity = self.shortcut(x)\n",
    "      # x : torch.Size([1, 64, 32, 32])\n",
    "        output = F.relu(self.bn1(self.conv1(x))) # torch.Size([1, 64, 30, 30]) -> padding 추가(short cut에서 더해주려면)\n",
    "        # print(output.shape)\n",
    "        output = self.bn2(self.conv2(output)) # torch.Size([1, 64, 28, 28])\n",
    "        # print(output.shape)\n",
    "\n",
    "        # skip connection\n",
    "        # print(x.shape)\n",
    "        output +=identity\n",
    "        output = F.relu(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"ResNet-50, 101, 152에서 사용\"\"\"\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, option='B'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1x1 conv\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # 3x3 conv\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # 1x1 conv (expansion=4 / 4배 확장 64 -> 256, 128 -> 512, 256 -> 1024, 512 -> 2048)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            if option == 'A':\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(\n",
    "                        x[:, :, ::stride, ::stride],\n",
    "                        (0, 0, 0, 0, 0, out_channels * self.expansion - in_channels),\n",
    "                        \"constant\", 0\n",
    "                    )\n",
    "                )\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels * self.expansion,\n",
    "                            kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels * self.expansion)\n",
    "                )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    # block -> Basic Block, num_blocks는 각 block개수 list형태로 [3,3,5,2]\n",
    "    def __init__(self, block, num_blocks, in_channels=3, num_classes=10, option='B'):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.option = option\n",
    "\n",
    "        # 초기 conv (논문상의 ImageNet은 7x7로 conv, 3x3 max pool을 통해 downsampling 함)\n",
    "        # 그러나 우리 데이터 cifar 10은 32x32 이므로 최소화\n",
    "        self.conv1 = nn.Conv2d(3,64,kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # 4개의 residual layers (64, 128, 256, 512)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1) # \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "\n",
    "        # 첫번째 block 쌓기 (stride 적용, 채널수도 변경 가능)\n",
    "        # block 의 인자들 self,in_channels, out_channels,stride, option=\"B\"\n",
    "        layers.append(block(self.in_channels, out_channels, stride, option = self.option))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        # 두번째 block부터는 무조건 stride=1, 채널수 동일하게 유지시키기\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, stride=1, option = self.option))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "        \n",
    "        output = self.avgpool(output) \n",
    "        # print(\"avgpool\", output.shape)\n",
    "        # #적용후 tensor shape : [B, 512, 1, 1] -> flatten 필요 \n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.fc(output)\n",
    "        # print(output.shape)\n",
    "\n",
    "        # output = self.fc(self.avgpool(output))\n",
    "        return output\n",
    "\n",
    "\n",
    "    def summary(self, input_shape=(32, 32, 3)):\n",
    "        \"\"\"\n",
    "        모델의 summary 출력\n",
    "        \n",
    "        Args:\n",
    "            input_shape: 입력 shape (height, width, channels)\n",
    "        \"\"\"\n",
    "        # PyTorch 형식으로 변환: (C, H, W)\n",
    "        h, w, c = input_shape\n",
    "        print(torch_summary(self, input_size=(1, c, h, w), \n",
    "                        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "                        depth=3))\n",
    "\n",
    "\n",
    "configuration = {\n",
    "    'resnet34': {\n",
    "        'block': BasicBlock,\n",
    "        'num_blocks': [3, 4, 6, 3]\n",
    "    },\n",
    "\n",
    "    # 'resnet34_plain': {\n",
    "        \n",
    "    # }\n",
    "\n",
    "    'resnet50': {\n",
    "        'block': BottleneckBlock,\n",
    "        'num_blocks': [3, 4, 6, 3]\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "def build_resnet(input_shape, is_50, num_classes=1000, option='B'):\n",
    "    h, w, c = input_shape\n",
    "\n",
    "    if is_50:\n",
    "        config = configuration['resnet50']\n",
    "        model_name = 'ResNet-50'\n",
    "    else:\n",
    "        config = configuration['resnet34']\n",
    "        model_name = 'ResNet-34'\n",
    "\n",
    "    model = ResNet(\n",
    "        block = config['block'],\n",
    "        num_blocks = config['num_blocks'],\n",
    "        in_channels = c,\n",
    "        num_classes = num_classes,\n",
    "        option = option\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "ResNet                                   [1, 3, 32, 32]            [1, 1000]                 --\n",
      "├─Conv2d: 1-1                            [1, 3, 32, 32]            [1, 64, 32, 32]           1,792\n",
      "├─BatchNorm2d: 1-2                       [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "├─Sequential: 1-3                        [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    └─BasicBlock: 2-1                   [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    └─Sequential: 3-1              [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-2                  [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-4                  [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-5             [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    └─BasicBlock: 2-2                   [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    └─Sequential: 3-6              [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-7                  [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-9                  [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-10            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    └─BasicBlock: 2-3                   [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    └─Sequential: 3-11             [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-12                 [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-13            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-14                 [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "├─Sequential: 1-4                        [1, 64, 32, 32]           [1, 128, 16, 16]          --\n",
      "│    └─BasicBlock: 2-4                   [1, 64, 32, 32]           [1, 128, 16, 16]          --\n",
      "│    │    └─Sequential: 3-16             [1, 64, 32, 32]           [1, 128, 16, 16]          8,448\n",
      "│    │    └─Conv2d: 3-17                 [1, 64, 32, 32]           [1, 128, 16, 16]          73,728\n",
      "│    │    └─BatchNorm2d: 3-18            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-19                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-20            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    └─BasicBlock: 2-5                   [1, 128, 16, 16]          [1, 128, 16, 16]          --\n",
      "│    │    └─Sequential: 3-21             [1, 128, 16, 16]          [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-22                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-24                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-25            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    └─BasicBlock: 2-6                   [1, 128, 16, 16]          [1, 128, 16, 16]          --\n",
      "│    │    └─Sequential: 3-26             [1, 128, 16, 16]          [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-27                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-28            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-29                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-30            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    └─BasicBlock: 2-7                   [1, 128, 16, 16]          [1, 128, 16, 16]          --\n",
      "│    │    └─Sequential: 3-31             [1, 128, 16, 16]          [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-32                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-33            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-34                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "├─Sequential: 1-5                        [1, 128, 16, 16]          [1, 256, 8, 8]            --\n",
      "│    └─BasicBlock: 2-8                   [1, 128, 16, 16]          [1, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-36             [1, 128, 16, 16]          [1, 256, 8, 8]            33,280\n",
      "│    │    └─Conv2d: 3-37                 [1, 128, 16, 16]          [1, 256, 8, 8]            294,912\n",
      "│    │    └─BatchNorm2d: 3-38            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-39                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-40            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    └─BasicBlock: 2-9                   [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-41             [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-42                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-43            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-44                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-45            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    └─BasicBlock: 2-10                  [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-46             [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-47                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-48            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-49                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-50            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    └─BasicBlock: 2-11                  [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-51             [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-52                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-53            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-54                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-55            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    └─BasicBlock: 2-12                  [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-56             [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-57                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-58            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-59                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-60            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    └─BasicBlock: 2-13                  [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-61             [1, 256, 8, 8]            [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-62                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-63            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-64                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-65            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "├─Sequential: 1-6                        [1, 256, 8, 8]            [1, 512, 4, 4]            --\n",
      "│    └─BasicBlock: 2-14                  [1, 256, 8, 8]            [1, 512, 4, 4]            --\n",
      "│    │    └─Sequential: 3-66             [1, 256, 8, 8]            [1, 512, 4, 4]            132,096\n",
      "│    │    └─Conv2d: 3-67                 [1, 256, 8, 8]            [1, 512, 4, 4]            1,179,648\n",
      "│    │    └─BatchNorm2d: 3-68            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-69                 [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-70            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    └─BasicBlock: 2-15                  [1, 512, 4, 4]            [1, 512, 4, 4]            --\n",
      "│    │    └─Sequential: 3-71             [1, 512, 4, 4]            [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-72                 [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-73            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-74                 [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-75            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    └─BasicBlock: 2-16                  [1, 512, 4, 4]            [1, 512, 4, 4]            --\n",
      "│    │    └─Sequential: 3-76             [1, 512, 4, 4]            [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-77                 [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-78            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-79                 [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-80            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "├─AdaptiveAvgPool2d: 1-7                 [1, 512, 4, 4]            [1, 512, 1, 1]            --\n",
      "├─Linear: 1-8                            [1, 512]                  [1, 1000]                 513,000\n",
      "===================================================================================================================\n",
      "Total params: 21,790,056\n",
      "Trainable params: 21,790,056\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.16\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 16.39\n",
      "Params size (MB): 87.16\n",
      "Estimated Total Size (MB): 103.56\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32,32,3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "ResNet                                   [1, 3, 32, 32]            [1, 10]                   --\n",
      "├─Conv2d: 1-1                            [1, 3, 32, 32]            [1, 64, 32, 32]           1,792\n",
      "├─BatchNorm2d: 1-2                       [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "├─Sequential: 1-3                        [1, 64, 32, 32]           [1, 256, 32, 32]          --\n",
      "│    └─BottleneckBlock: 2-1              [1, 64, 32, 32]           [1, 256, 32, 32]          --\n",
      "│    │    └─Sequential: 3-1              [1, 64, 32, 32]           [1, 256, 32, 32]          16,896\n",
      "│    │    └─Conv2d: 3-2                  [1, 64, 32, 32]           [1, 64, 32, 32]           4,096\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-4                  [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-5             [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-6                  [1, 64, 32, 32]           [1, 256, 32, 32]          16,384\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 256, 32, 32]          [1, 256, 32, 32]          512\n",
      "│    └─BottleneckBlock: 2-2              [1, 256, 32, 32]          [1, 256, 32, 32]          --\n",
      "│    │    └─Sequential: 3-8              [1, 256, 32, 32]          [1, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-9                  [1, 256, 32, 32]          [1, 64, 32, 32]           16,384\n",
      "│    │    └─BatchNorm2d: 3-10            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-11                 [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-12            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-13                 [1, 64, 32, 32]           [1, 256, 32, 32]          16,384\n",
      "│    │    └─BatchNorm2d: 3-14            [1, 256, 32, 32]          [1, 256, 32, 32]          512\n",
      "│    └─BottleneckBlock: 2-3              [1, 256, 32, 32]          [1, 256, 32, 32]          --\n",
      "│    │    └─Sequential: 3-15             [1, 256, 32, 32]          [1, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-16                 [1, 256, 32, 32]          [1, 64, 32, 32]           16,384\n",
      "│    │    └─BatchNorm2d: 3-17            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-18                 [1, 64, 32, 32]           [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    └─Conv2d: 3-20                 [1, 64, 32, 32]           [1, 256, 32, 32]          16,384\n",
      "│    │    └─BatchNorm2d: 3-21            [1, 256, 32, 32]          [1, 256, 32, 32]          512\n",
      "├─Sequential: 1-4                        [1, 256, 32, 32]          [1, 512, 16, 16]          --\n",
      "│    └─BottleneckBlock: 2-4              [1, 256, 32, 32]          [1, 512, 16, 16]          --\n",
      "│    │    └─Sequential: 3-22             [1, 256, 32, 32]          [1, 512, 16, 16]          132,096\n",
      "│    │    └─Conv2d: 3-23                 [1, 256, 32, 32]          [1, 128, 32, 32]          32,768\n",
      "│    │    └─BatchNorm2d: 3-24            [1, 128, 32, 32]          [1, 128, 32, 32]          256\n",
      "│    │    └─Conv2d: 3-25                 [1, 128, 32, 32]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-26            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-27                 [1, 128, 16, 16]          [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-28            [1, 512, 16, 16]          [1, 512, 16, 16]          1,024\n",
      "│    └─BottleneckBlock: 2-5              [1, 512, 16, 16]          [1, 512, 16, 16]          --\n",
      "│    │    └─Sequential: 3-29             [1, 512, 16, 16]          [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-30                 [1, 512, 16, 16]          [1, 128, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-32                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-33            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-34                 [1, 128, 16, 16]          [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 512, 16, 16]          [1, 512, 16, 16]          1,024\n",
      "│    └─BottleneckBlock: 2-6              [1, 512, 16, 16]          [1, 512, 16, 16]          --\n",
      "│    │    └─Sequential: 3-36             [1, 512, 16, 16]          [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-37                 [1, 512, 16, 16]          [1, 128, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-38            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-39                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-40            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-41                 [1, 128, 16, 16]          [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-42            [1, 512, 16, 16]          [1, 512, 16, 16]          1,024\n",
      "│    └─BottleneckBlock: 2-7              [1, 512, 16, 16]          [1, 512, 16, 16]          --\n",
      "│    │    └─Sequential: 3-43             [1, 512, 16, 16]          [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-44                 [1, 512, 16, 16]          [1, 128, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-45            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-46                 [1, 128, 16, 16]          [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-47            [1, 128, 16, 16]          [1, 128, 16, 16]          256\n",
      "│    │    └─Conv2d: 3-48                 [1, 128, 16, 16]          [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-49            [1, 512, 16, 16]          [1, 512, 16, 16]          1,024\n",
      "├─Sequential: 1-5                        [1, 512, 16, 16]          [1, 1024, 8, 8]           --\n",
      "│    └─BottleneckBlock: 2-8              [1, 512, 16, 16]          [1, 1024, 8, 8]           --\n",
      "│    │    └─Sequential: 3-50             [1, 512, 16, 16]          [1, 1024, 8, 8]           526,336\n",
      "│    │    └─Conv2d: 3-51                 [1, 512, 16, 16]          [1, 256, 16, 16]          131,072\n",
      "│    │    └─BatchNorm2d: 3-52            [1, 256, 16, 16]          [1, 256, 16, 16]          512\n",
      "│    │    └─Conv2d: 3-53                 [1, 256, 16, 16]          [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-54            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-55                 [1, 256, 8, 8]            [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-56            [1, 1024, 8, 8]           [1, 1024, 8, 8]           2,048\n",
      "│    └─BottleneckBlock: 2-9              [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Sequential: 3-57             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-58                 [1, 1024, 8, 8]           [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-59            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-60                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-61            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-62                 [1, 256, 8, 8]            [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-63            [1, 1024, 8, 8]           [1, 1024, 8, 8]           2,048\n",
      "│    └─BottleneckBlock: 2-10             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Sequential: 3-64             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-65                 [1, 1024, 8, 8]           [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-66            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-67                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-68            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-69                 [1, 256, 8, 8]            [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-70            [1, 1024, 8, 8]           [1, 1024, 8, 8]           2,048\n",
      "│    └─BottleneckBlock: 2-11             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Sequential: 3-71             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-72                 [1, 1024, 8, 8]           [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-73            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-74                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-75            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-76                 [1, 256, 8, 8]            [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-77            [1, 1024, 8, 8]           [1, 1024, 8, 8]           2,048\n",
      "│    └─BottleneckBlock: 2-12             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Sequential: 3-78             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-79                 [1, 1024, 8, 8]           [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-80            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-81                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-82            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-83                 [1, 256, 8, 8]            [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-84            [1, 1024, 8, 8]           [1, 1024, 8, 8]           2,048\n",
      "│    └─BottleneckBlock: 2-13             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Sequential: 3-85             [1, 1024, 8, 8]           [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-86                 [1, 1024, 8, 8]           [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-87            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-88                 [1, 256, 8, 8]            [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-89            [1, 256, 8, 8]            [1, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-90                 [1, 256, 8, 8]            [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-91            [1, 1024, 8, 8]           [1, 1024, 8, 8]           2,048\n",
      "├─Sequential: 1-6                        [1, 1024, 8, 8]           [1, 2048, 4, 4]           --\n",
      "│    └─BottleneckBlock: 2-14             [1, 1024, 8, 8]           [1, 2048, 4, 4]           --\n",
      "│    │    └─Sequential: 3-92             [1, 1024, 8, 8]           [1, 2048, 4, 4]           2,101,248\n",
      "│    │    └─Conv2d: 3-93                 [1, 1024, 8, 8]           [1, 512, 8, 8]            524,288\n",
      "│    │    └─BatchNorm2d: 3-94            [1, 512, 8, 8]            [1, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-95                 [1, 512, 8, 8]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-96            [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-97                 [1, 512, 4, 4]            [1, 2048, 4, 4]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-98            [1, 2048, 4, 4]           [1, 2048, 4, 4]           4,096\n",
      "│    └─BottleneckBlock: 2-15             [1, 2048, 4, 4]           [1, 2048, 4, 4]           --\n",
      "│    │    └─Sequential: 3-99             [1, 2048, 4, 4]           [1, 2048, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-100                [1, 2048, 4, 4]           [1, 512, 4, 4]            1,048,576\n",
      "│    │    └─BatchNorm2d: 3-101           [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-102                [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-103           [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-104                [1, 512, 4, 4]            [1, 2048, 4, 4]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-105           [1, 2048, 4, 4]           [1, 2048, 4, 4]           4,096\n",
      "│    └─BottleneckBlock: 2-16             [1, 2048, 4, 4]           [1, 2048, 4, 4]           --\n",
      "│    │    └─Sequential: 3-106            [1, 2048, 4, 4]           [1, 2048, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-107                [1, 2048, 4, 4]           [1, 512, 4, 4]            1,048,576\n",
      "│    │    └─BatchNorm2d: 3-108           [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-109                [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-110           [1, 512, 4, 4]            [1, 512, 4, 4]            1,024\n",
      "│    │    └─Conv2d: 3-111                [1, 512, 4, 4]            [1, 2048, 4, 4]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-112           [1, 2048, 4, 4]           [1, 2048, 4, 4]           4,096\n",
      "├─AdaptiveAvgPool2d: 1-7                 [1, 2048, 4, 4]           [1, 2048, 1, 1]           --\n",
      "├─Linear: 1-8                            [1, 2048]                 [1, 10]                   20,490\n",
      "===================================================================================================================\n",
      "Total params: 23,520,906\n",
      "Trainable params: 23,520,906\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.30\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 54.92\n",
      "Params size (MB): 94.08\n",
      "Estimated Total Size (MB): 149.02\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "resnet_50 = build_resnet(input_shape=(32, 32,3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCH = 15\n",
    "\n",
    "# CIFAR-10 데이터셋에 대해 Normalize와 Tensor 변환을 적용하는 코드\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # VGG-16 표준 정규화\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Accuracy: 30.24%\n",
      "Epoch 1: Validation Accuracy: 40.99%\n",
      "Epoch 2: Train Accuracy: 47.73%\n",
      "Epoch 2: Validation Accuracy: 50.73%\n",
      "Epoch 3: Train Accuracy: 56.73%\n",
      "Epoch 3: Validation Accuracy: 57.08%\n",
      "Epoch 4: Train Accuracy: 63.73%\n",
      "Epoch 4: Validation Accuracy: 58.83%\n",
      "Epoch 5: Train Accuracy: 69.57%\n",
      "Epoch 5: Validation Accuracy: 61.46%\n",
      "Epoch 6: Train Accuracy: 75.24%\n",
      "Epoch 6: Validation Accuracy: 59.77%\n",
      "Epoch 7: Train Accuracy: 81.10%\n",
      "Epoch 7: Validation Accuracy: 65.32%\n",
      "Epoch 8: Train Accuracy: 86.74%\n",
      "Epoch 8: Validation Accuracy: 61.96%\n",
      "Epoch 9: Train Accuracy: 90.86%\n",
      "Epoch 9: Validation Accuracy: 63.64%\n",
      "Epoch 10: Train Accuracy: 94.27%\n",
      "Epoch 10: Validation Accuracy: 64.41%\n",
      "Epoch 11: Train Accuracy: 97.24%\n",
      "Epoch 11: Validation Accuracy: 61.69%\n",
      "Epoch 12: Train Accuracy: 98.51%\n",
      "Epoch 12: Validation Accuracy: 65.71%\n",
      "Epoch 13: Train Accuracy: 99.52%\n",
      "Epoch 13: Validation Accuracy: 66.46%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 32\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "current_time = time.time()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet_34 = build_resnet(input_shape=(3,32,32), is_50=False)\n",
    "\n",
    "# resnet_34 = torchvision.models.vgg16(pretrained=True)\n",
    "resnet_34.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet_34.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "resnet_34_train_losses = []\n",
    "resnet_34_val_accuracy = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    resnet_34.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_34(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / (i+1):.3f}\")\n",
    "        \n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    resnet_34_train_losses.append(train_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    resnet_34.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet_34(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    resnet_34_val_accuracy.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(time.time() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
